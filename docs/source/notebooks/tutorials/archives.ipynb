{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fc5e39",
   "metadata": {},
   "source": [
    "# Creating and interacting with a DAXA Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec471d",
   "metadata": {},
   "source": [
    "This tutorial will explain the basic concepts behind the second type of important class in DAXA, the Archive class (with mission classes being the first type, see [the missions tutorial](missions.html)). DAXA Archives are what manage the datasets that we download from various missions, enabling easy access and greatly simplifying processing/reduction - they allow you to stop thinking about all the files and settings that any large dataset entails.\n",
    "\n",
    "We will cover the following:\n",
    "\n",
    "* Setting up an Archive from scratch, using filtered DAXA missions.\n",
    "* Loading an existing Archive from disk.\n",
    "* The properties of an Archive.\n",
    "* Accessing processing logs and success information (though we do not cover processing in this part of the documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cadd97e",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858d8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daxa.mission import XMMPointed, Chandra, eRASS1DE, ROSATPointed\n",
    "from daxa.archive import Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeee76",
   "metadata": {},
   "source": [
    "## What is a DAXA archive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc2c89",
   "metadata": {},
   "source": [
    "DAXA Archives take a set of filtered missions, make sure that their data are downloaded, and enable easy access and organisation of all data files and processing functions. Key functionality includes:\n",
    "\n",
    "* Storing the logs and errors of all processing steps (if run).\n",
    "* Allowing for their easy retrieval. \n",
    "* Managing the myriad files produced during the processing.\n",
    "* Keeping track of which processes failed for which data, ensuring that any further processing only runs on data that have successfully passed through the earlier processes.\n",
    "\n",
    "Archives can also be loaded back into DAXA at a later date, so that the processing logs of data that has since been found to be problematic can be easily inspected, or indeed so that processing steps can be re-run with different settings; this also allows for archives to be updated, if more data become available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03822d2",
   "metadata": {},
   "source": [
    "## Creating a new archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc71354",
   "metadata": {},
   "source": [
    "Here we will demonstrate how to set up a new DAXA Archive from scratch - this information can be combined with the [the missions tutorial](missions.html) and the <font color='red'>case studies</font> to create an archive from any dataset you might be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735d8bc",
   "metadata": {},
   "source": [
    "### Step 1 - Set up and filter missions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62c349",
   "metadata": {},
   "source": [
    "The first thing we have to do is to select the observations that we wish to include in the archive (and indeed the missions that we wish to include). The missions all have different characteristics, so your choice of which to include will be heavily dependent on your science case.\n",
    "\n",
    "Here we will create an archive of XMM, Chandra, eROSITA All-Sky DR1, and ROSAT pointed observations of a famous galaxy cluster (though the archive would behave the same if it held data for a large sample of objects).\n",
    "\n",
    "First of all, we define instances of the mission classes that we wish to include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c420fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = XMMPointed()\n",
    "ch = Chandra()\n",
    "er = eRASS1DE()\n",
    "rp = ROSATPointed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93c259",
   "metadata": {},
   "source": [
    "Then we filter them to only include observations of our cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm.filter_on_name(\"A3667\")\n",
    "ch.filter_on_name(\"A3667\")\n",
    "er.filter_on_name(\"A3667\")\n",
    "rp.filter_on_name(\"A3667\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4a0a9",
   "metadata": {},
   "source": [
    "We then download the available data (though the declaration of an Archive would also trigger this, we do it this way because we wish to download pre-generated products for Chandra and ROSAT pointed observations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70aa81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm.download()\n",
    "ch.download(download_products=True)\n",
    "er.download()\n",
    "rp.download(download_products=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f46205",
   "metadata": {},
   "source": [
    "### Step 2 - Setting up an Archive object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6838b87",
   "metadata": {},
   "source": [
    "Now we create the actual DAXA Archive instance - all this requires is for us to choose an archive name (which is what will be used to load it back in at a later date, if necessary) and to pass in the filtered missions that we have already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4450d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = Archive(\"A3667\", [xm, ch, er, rp], clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076142d",
   "metadata": {},
   "source": [
    "Now we've declared it, we can use the `info()` method to get a summary of its current status, including the amount of data available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178d880",
   "metadata": {},
   "source": [
    "### Step 3 - Processing the Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389083f",
   "metadata": {},
   "source": [
    "We're not actually going to cover _how_ to process things here, as each telescope tends to have its own backend software with a unique way of doing things; they each have their own processing tutorials, which will demonstrate both a one-line processing method, and how to control the reduction in more detail. Any processing method will take the archive object as an argument, and act on the data stored within it.\n",
    "\n",
    "So instead we include this step here to highlight that the next logical step after the creation of a new archive is to run processing and reduction routines, if raw data have been downloaded. The successful completion of this step will leave you with an archive of data that you can easily manage, access, and use for your scientific analyses.\n",
    "\n",
    "If you elected to download existing products (most missions support this), then only one processing step is necessary - this reorganises the downloaded data so that it is compatible with DAXA storage and file naming conventions. **It will have run automatically on declaration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454904e",
   "metadata": {},
   "source": [
    "### Note on saving Archives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158b983",
   "metadata": {},
   "source": [
    "Archive instances can be saved and loaded back in (as you'll see in the next section). This can be triggered manually by running the `save()` method, but __this shouldn't be generally necessary__ - this is because the archive is automatically saved upon first setup, and after every processing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1269a",
   "metadata": {},
   "source": [
    "## Loading an existing archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44310223",
   "metadata": {},
   "source": [
    "As we have intimated, previously created archives can be loaded back in to memory in exactly the same state as when they were saved. We will demonstrate this here with an archive we prepared earlier - it has had XMM processing applied, which will allow us to demonstrate the logging and management functionality. \n",
    "\n",
    "Reloading an archive has a number of possible applications:\n",
    "\n",
    "* Access to archive data management functions - e.g. locating specific data files, identifying what observations are available.\n",
    "* Checking processing logs - e.g. finding errors or warnings in the processing of data that has since been identified as problematic.\n",
    "* Updating the archive - either adding another mission, or using the archive to check for new data matching your original mission filtering operations (these are stored in the mission saves, so can be re-run automatically).\n",
    "\n",
    "All you need to do is set up an Archive instance and pass the name of an existing archive - this assumes your code is running in the same directory as it was originally, as Archives are stored in 'daxa_output' (if the DAXA configuration file hasn't been altered). The configuration can also be altered so that all DAXA outputs are stored in an absolute path, in which case defining an Archive object with the name of an existing dataset would work from any directory).\n",
    "\n",
    "Loading in an archive (note that you don't need to pass any missions, loading the archive back in will also reinstate the missions as they were when the Archive was last saved):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd54aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dt237/code/DAXA/daxa/mission/xmm.py:83: UserWarning: 140 of the 17678 observations located for this mission have been removed due to NaN RA or Dec values\n",
      "  self._fetch_obs_info()\n"
     ]
    }
   ],
   "source": [
    "prev_arch = Archive(\"PHL1811_made_earlier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3013c",
   "metadata": {},
   "source": [
    "Once again, we will run the `info()` method, but note that for this archive the XMM-Newton Pointed mission is marked as 'fully processed':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "893740c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------\n",
      "Number of missions - 4\n",
      "Total number of observations - 9\n",
      "Beginning of earliest observation - 1990-10-31 00:00:00\n",
      "End of latest observation - 2015-11-30 04:11:08.184002\n",
      "\n",
      "-- XMM-Newton Pointed --\n",
      "   Internal DAXA name - xmm_pointed\n",
      "   Chosen instruments - M1, M2, PN\n",
      "   Number of observations - 4\n",
      "   Fully Processed - False\n",
      "\n",
      "-- Chandra --\n",
      "   Internal DAXA name - chandra\n",
      "   Chosen instruments - ACIS-I, ACIS-S, HRC-I, HRC-S\n",
      "   Number of observations - 3\n",
      "   Fully Processed - False\n",
      "\n",
      "-- NuSTAR Pointed --\n",
      "   Internal DAXA name - nustar_pointed\n",
      "   Chosen instruments - FPMA, FPMB\n",
      "   Number of observations - 1\n",
      "   Fully Processed - False\n",
      "\n",
      "-- RASS --\n",
      "   Internal DAXA name - rosat_all_sky\n",
      "   Chosen instruments - PSPC\n",
      "   Number of observations - 1\n",
      "   Fully Processed - False\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev_arch.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30baa0",
   "metadata": {},
   "source": [
    "We note that it _is_ possible to declare an Archive with a previously used name and overwrite it - you just have to pass `clobber=True` when you declare the Archive instance. We print the docstring of the Archive class here for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd11ca60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The Archive class, which is to be used to consolidate and provide some interface with a set\n",
      "    of mission's data. Archives can be passed to processing and cleaning functions in DAXA, and also\n",
      "    contain convenience functions for accessing summaries of the available data.\n",
      "\n",
      "    :param str archive_name: The name to be given to this archive - it will be used for storage\n",
      "        and identification. If an existing archive with this name exists it will be read in, unless clobber=True.\n",
      "    :param List[BaseMission]/BaseMission missions: The mission, or missions, which are to be included\n",
      "        in this archive - any setup processes (i.e. the filtering of data to be acquired) should be\n",
      "        performed prior to creating an archive. The default value is None, but this should be set for any new\n",
      "        archives, it can only be left as None if an existing archive is being read back in.\n",
      "    :param bool clobber: If an archive named 'archive_name' already exists, then setting clobber to True\n",
      "        will cause it to be deleted and overwritten.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(Archive.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a97730",
   "metadata": {},
   "source": [
    "## Accessing component missions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e56dd",
   "metadata": {},
   "source": [
    "The missions that were used to create an archive can be retrieved, giving access to their information tables - note that you cannot just use the filtering methods of a mission to change the data in the archive; altering the observations in an archive requires using <font color='red'>the archive `update()` method.</font>\n",
    "\n",
    "To retrieve a mission you can either address the archive with the DAXA internal name of the mission, or get the whole list using the `missions` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ef9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<daxa.mission.xmm.XMMPointed at 0x7fdaf9af12b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch['xmm_pointed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302c8800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<daxa.mission.xmm.XMMPointed at 0x7fdaf9af12b0>,\n",
       " <daxa.mission.chandra.Chandra at 0x7fdb18ffc0a0>,\n",
       " <daxa.mission.nustar.NuSTARPointed at 0x7fdb1977a280>,\n",
       " <daxa.mission.rosat.ROSATAllSky at 0x7fdb19de2790>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efd20f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>ObsID</th>\n",
       "      <th>start</th>\n",
       "      <th>science_usable</th>\n",
       "      <th>duration</th>\n",
       "      <th>proprietary_end_date</th>\n",
       "      <th>revolution</th>\n",
       "      <th>proprietary_usable</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>157.74630</td>\n",
       "      <td>31.048890</td>\n",
       "      <td>0102041001</td>\n",
       "      <td>2000-12-07 04:57:14</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 01:30:06</td>\n",
       "      <td>2002-04-06 00:00:00</td>\n",
       "      <td>182</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-12-07 06:27:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>328.75620</td>\n",
       "      <td>-9.373528</td>\n",
       "      <td>0204310101</td>\n",
       "      <td>2004-11-01 09:06:42</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 09:08:39</td>\n",
       "      <td>2005-12-01 00:00:00</td>\n",
       "      <td>897</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-11-01 18:15:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>234.89625</td>\n",
       "      <td>-83.593060</td>\n",
       "      <td>0502671101</td>\n",
       "      <td>2008-04-01 17:24:48</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 05:25:20</td>\n",
       "      <td>2009-05-29 00:00:00</td>\n",
       "      <td>1522</td>\n",
       "      <td>True</td>\n",
       "      <td>2008-04-01 22:50:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>328.75625</td>\n",
       "      <td>-9.373333</td>\n",
       "      <td>0761910201</td>\n",
       "      <td>2015-11-29 09:38:07</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 16:30:00</td>\n",
       "      <td>2016-12-11 23:00:00</td>\n",
       "      <td>2925</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-11-30 02:08:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ra        dec       ObsID               start  science_usable  \\\n",
       "922    157.74630  31.048890  0102041001 2000-12-07 04:57:14            True   \n",
       "3802   328.75620  -9.373528  0204310101 2004-11-01 09:06:42            True   \n",
       "6014   234.89625 -83.593060  0502671101 2008-04-01 17:24:48            True   \n",
       "12006  328.75625  -9.373333  0761910201 2015-11-29 09:38:07            True   \n",
       "\n",
       "             duration proprietary_end_date  revolution  proprietary_usable  \\\n",
       "922   0 days 01:30:06  2002-04-06 00:00:00         182                True   \n",
       "3802  0 days 09:08:39  2005-12-01 00:00:00         897                True   \n",
       "6014  0 days 05:25:20  2009-05-29 00:00:00        1522                True   \n",
       "12006 0 days 16:30:00  2016-12-11 23:00:00        2925                True   \n",
       "\n",
       "                      end  \n",
       "922   2000-12-07 06:27:20  \n",
       "3802  2004-11-01 18:15:21  \n",
       "6014  2008-04-01 22:50:08  \n",
       "12006 2015-11-30 02:08:07  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch['xmm_pointed'].filtered_obs_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c60fde",
   "metadata": {},
   "source": [
    "## Archive properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101cd2e",
   "metadata": {},
   "source": [
    "Here we run through the general properties of the archive class, summarising their meaning and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605eaf1",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0300055",
   "metadata": {},
   "source": [
    "The `archive_name` class returns the name that was given to the archive on creation - this cannot be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4ef310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHL1811_made_earlier'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.archive_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c201f",
   "metadata": {},
   "source": [
    "### Archive Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6dddb8",
   "metadata": {},
   "source": [
    "This property (`archive_path`) returns the absolute path to the top level of this archive's storage directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59e75cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.archive_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9684d",
   "metadata": {},
   "source": [
    "### Mission Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a8a28",
   "metadata": {},
   "source": [
    "In addition to the `missions` property discussed earlier, we include a `mission_names` property which lists the internal names of the mission classes associated with the archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c687964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xmm_pointed', 'chandra', 'nustar_pointed', 'rosat_all_sky']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.mission_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e6e7b",
   "metadata": {},
   "source": [
    "## Processing-related Archive properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7eb20",
   "metadata": {},
   "source": [
    "This section deals with Archive properties that are related to processing of the available data into something scientifically useful - this is why we loaded an existing archive with processing applied, to demonstrate the contents of these properties:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057718dd",
   "metadata": {},
   "source": [
    "### Process Success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3347eb",
   "metadata": {},
   "source": [
    "The `process_success` property is very important - it is a nested dictionary which records which processing steps were 'successful' (usually defined as no errors being detected, and expected files being found) for which data. Those that were successful have a boolean value of True, those that weren't have a boolean value of False.\n",
    "\n",
    "Top level keys will always be mission name, the next level down will be the process name, and the layer below that will be the unique IDs of the data the process acted on. This is often an ObsID, but can also be ObsID + instrument name, or ObsID + instrument name + sub-exposure ID.\n",
    "\n",
    "This allows you (but more importantly the archive itself) to know which stages have failed for which data - that in turn means any processing that is dependent on a previous stage can know which data to skip. All this ensures no interruptions when reducing large sets of data.\n",
    "\n",
    "In this case we've run all processing steps on the XMM data in the archive, note the following entries:\n",
    "* `espfilt` 0502671101PNS003 \n",
    "* `espfilt` 0502671101M2S002\n",
    "\n",
    "Both failed safely, and were not considered for the next processing stages. Also note that the ObsID 0102041001 does not appear after the `odf_ingest` step, as all of its data was taken in CalClosed mode and can't be used for the study of the target objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b622a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xmm_pointed': {'cif_build': {'0204310101': True,\n",
       "   '0102041001': True,\n",
       "   '0761910201': True,\n",
       "   '0502671101': True},\n",
       "  'odf_ingest': {'0102041001': True,\n",
       "   '0502671101': True,\n",
       "   '0204310101': True,\n",
       "   '0761910201': True},\n",
       "  'epchain': {'0502671101PNS003': True,\n",
       "   '0204310101PNS003': True,\n",
       "   '0761910201PNS003': True},\n",
       "  'emchain': {'0502671101M1S001': True,\n",
       "   '0204310101M1S001': True,\n",
       "   '0502671101M2S002': True,\n",
       "   '0204310101M2S002': True,\n",
       "   '0761910201M2S002': True,\n",
       "   '0761910201M1S001': True},\n",
       "  'espfilt': {'0502671101M2S002': False,\n",
       "   '0204310101M1S001': True,\n",
       "   '0204310101M2S002': True,\n",
       "   '0502671101M1S001': True,\n",
       "   '0761910201M1S001': True,\n",
       "   '0761910201M2S002': True,\n",
       "   '0502671101PNS003': False,\n",
       "   '0204310101PNS003': True,\n",
       "   '0761910201PNS003': True},\n",
       "  'cleaned_evt_lists': {'0204310101M2S002': True,\n",
       "   '0761910201M1S001': True,\n",
       "   '0204310101M1S001': True,\n",
       "   '0502671101M1S001': True,\n",
       "   '0761910201M2S002': True,\n",
       "   '0204310101PNS003': True,\n",
       "   '0761910201PNS003': True},\n",
       "  'merge_subexposures': {'0204310101M1': True,\n",
       "   '0761910201M1': True,\n",
       "   '0204310101PN': True,\n",
       "   '0502671101M1': True,\n",
       "   '0204310101M2': True,\n",
       "   '0761910201M2': True,\n",
       "   '0761910201PN': True}},\n",
       " 'chandra': {},\n",
       " 'nustar_pointed': {},\n",
       " 'rosat_all_sky': {}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.process_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbd34e",
   "metadata": {},
   "source": [
    "### Process Logs (stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505389a",
   "metadata": {},
   "source": [
    "All of the logs for all processes run by DAXA are stored, and can be accessed through the `process_logs` property - this is structured in the exact same way as `process_success`, as a nested dictionary. The only difference here is that the final values are strings rather than booleans.\n",
    "\n",
    "We show the log for a single process applied to a single piece of data, otherwise this tutorial document would be very long indeed - this particular process worked perfectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ee70b85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "espfilt:- Executing (routine): espfilt eventfile=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT withoot=no ootfile=dataset method=histogram withsmoothing=yes smooth=51 withbinning=yes binsize=60 ratio=1.2 withlongnames=yes elow=2500 ehigh=8500 rangescale=6 allowsigma=3 limits='0.1 6.5' keepinterfiles=no  -w 1 -V 4\n",
      "espfilt:- espfilt (espfilt-4.3)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:37.000\n",
      "espfilt:-  ESPFILT: Processing eventlist: /Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT\n",
      "espfilt:-  *FOV IMAGE* = mos1S001-fovim-2500-8500.fits\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT filteredset=filtered.fits withfilteredset=no keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression=true filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=mos1S001-fovim-2500-8500.fits xcolumn=DETX ycolumn=DETY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=yes spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:37.000\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:37.000\n",
      "espfilt:-  Running evselect to create *FOV LIGHTCURVE*\n",
      "espfilt:-  *FOV LIGHTCURVE * = mos1S001-fovlc-2500-8500.fits\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT:EVENTS filteredset=filtered.fits withfilteredset=yes keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression='(PATTERN<=12)&&(PI in [2500:8500])&&(#XMMEA_EM)' filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=image.fits xcolumn=RAWX ycolumn=RAWY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=no spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=mos1S001-fovlc-2500-8500.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=yes makeratecolumn=yes withrateset=yes histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:38.000\n",
      "evselect:- selected 31994 rows from the input table.\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:38.000\n",
      "espfilt:-  Running evselect to create *CORNER EVENTLIST*\n",
      "espfilt:-  *CORNER EVENTLIST * = mos1S001-corev-2500-8500.fits\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT:EVENTS filteredset=mos1S001-corev-2500-8500.fits withfilteredset=yes keepfilteroutput=yes flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression='(PATTERN<=12)&&((FLAG & 0x766aa000)==0)&&!(CIRCLE(100,-200,17700,DETX,DETY)||CIRCLE(834,135,17100,DETX,DETY)||CIRCLE(770,-803,17100,DETX,DETY)||BOX(-20,-17000,6500,500,0,DETX,DETY)||BOX(5880,-20500,7500,1500,10,DETX,DETY)||BOX(-5920,-20500,7500,1500,350,DETX,DETY)||BOX(-20,-20000,5500,500,0,DETX,DETY)||BOX(-12900,16000,250,4000,0,DETX,DETY)||BOX(80,18600,150,1300,0,DETX,DETY)||BOX(-10,-18800,125,1500,0,DETX,DETY))' filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=image.fits xcolumn=RAWX ycolumn=RAWY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=no spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:38.000\n",
      "evselect:- selected 14633 rows from the input table.\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:39.000\n",
      "espfilt:-  Running evselect to create *CORNER IMAGE*\n",
      "espfilt:-  *CORNER IMAGE * = mos1S001-corim-2500-8500.fits\n",
      "evselect:- Executing (routine): evselect table=mos1S001-corev-2500-8500.fits filteredset=filtered.fits withfilteredset=no keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression=true filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=mos1S001-corim-2500-8500.fits xcolumn=DETX ycolumn=DETY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=yes spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:39.000\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:39.000\n",
      "espfilt:-  Running evselect to create *CORNER LIGHTCURVE*\n",
      "espfilt:-  *CORNER LIGHTCURVE * = mos1S001-corlc-2500-8500.fits\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT:EVENTS filteredset=filtered.fits withfilteredset=yes keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression='(PATTERN<=12)&&(PI in [2500:8500])&&((FLAG & 0x766aa000)==0)&&!(CIRCLE(100,-200,17700,DETX,DETY)||CIRCLE(834,135,17100,DETX,DETY)||CIRCLE(770,-803,17100,DETX,DETY)||BOX(-20,-17000,6500,500,0,DETX,DETY)||BOX(5880,-20500,7500,1500,10,DETX,DETY)||BOX(-5920,-20500,7500,1500,350,DETX,DETY)||BOX(-20,-20000,5500,500,0,DETX,DETY)||BOX(-12900,16000,250,4000,0,DETX,DETY)||BOX(80,18600,150,1300,0,DETX,DETY)||BOX(-10,-18800,125,1500,0,DETX,DETY))' filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=image.fits xcolumn=RAWX ycolumn=RAWY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=no spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=mos1S001-corlc-2500-8500.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=yes makeratecolumn=yes withrateset=yes histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:40.000\n",
      "evselect:- selected 4961 rows from the input table.\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:40.000\n",
      "espfilt:-  ESPFILT: Processing using the HISTOGRAM method.\n",
      "espfilt:-  CLEAN_LC: There are        32670  rows in the FOV LC\n",
      "espfilt:-  Starting Multidimensional minimzation of fit_gauss (amoeba)\n",
      "espfilt:- plim(1:2) =   0.1000   6.5000\n",
      "espfilt:- **** sortarray max bins    =   663 histo binwidth =    0.0196\n",
      "espfilt:- **** sortarray actual bins (nverls) =   658\n",
      "espfilt:- min LC value=    0.000 max LC value =    3.392 limits(2) =    6.500\n",
      "espfilt:- ***** pre-amoeba: low =   30 peak =    35 high =    42 delta =    13\n",
      "espfilt:- ***** pre-amoeba: cnts(low) = 1173 cnts(peak) =  1250 cnts(high) =   881\n",
      "espfilt:-  pre-amoeba parms =  1250.000    0.767    0.100\n",
      "espfilt:- \n",
      "espfilt:- 1st rl =  1248.584    0.749    0.180 / rh =  1248.584    0.749    0.180\n",
      "espfilt:- 1st cl =   776.565 / ch =   776.565\n",
      "espfilt:- ***** 2nd amoeba: low =   29 peak =    34 high =    41\n",
      "espfilt:- ***** 2nd amoeba: cnts(low) = 1046 cnts(peak)=  1222 cnts(high) =   915\n",
      "espfilt:-  2nd parms =  1222.000    0.747    0.100\n",
      "espfilt:- 2nd rl =  1252.878    0.750    0.173 / rh =  1252.878    0.750    0.173\n",
      "espfilt:- 2nd cl =   735.384 / ch =   735.384\n",
      "espfilt:- ***** 3rd amoeba: low =   29 peak =    34 high =    41\n",
      "espfilt:- ***** 3rd amoeba: cnts(low) = 1046 cnts(peak)=  1222 cnts(high) =   915\n",
      "espfilt:-  3rd parms =  1222.000    0.747    0.100\n",
      "espfilt:- 3rd rl =  1252.878    0.750    0.173 / rh =  1252.878    0.750    0.173\n",
      "espfilt:- 3rd cl =   735.384 / ch =   735.384\n",
      "espfilt:- H_IMME =  0.647     H_TOTL = 0.2405     L_IMME = 0.6711     L_TOTL = -.1474\n",
      "espfilt:- WRITE_QDP_GTI: Norm =  1252.878 Width =     0.173 Center =     0.750\n",
      "gtibuild:- Executing (routine): gtibuild file=mos1S001-gti-2500-8500.txt table=mos1S001-gti-2500-8500.fits  -w 1 -V 4\n",
      "gtibuild:- gtibuild (gtibuild-1.5)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:41.000\n",
      "gtibuild:- gtibuild (gtibuild-1.5)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:41.000\n",
      "espfilt:-  HISTOGRAM_METHOD: *CLEANED (flare-free) FOV EVENTLIST FILE* = mos1S001-allevc-2500-8500.fits\n",
      "espfilt:-  *Flare free eventlist evselect command =\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT filteredset=mos1S001-allevc-2500-8500.fits withfilteredset=yes keepfilteroutput=yes flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression='(PATTERN<=12)&&GTI(mos1S001-gti-2500-8500.fits,TIME)&&((FLAG & 0x766aa000)==0)' filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=image.fits xcolumn=RAWX ycolumn=RAWY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=no spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:41.000\n",
      "evselect:- selected 90501 rows from the input table.\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:41.000\n",
      "espfilt:-  HISTOGRAM_METHOD: *CLEANED (flare-free) FOV IMAGE FILE* = mos1S001-allimc-2500-8500.fits\n",
      "espfilt:-  *Flare free FOV image evselect command =\n",
      "evselect:- Executing (routine): evselect table=mos1S001-allevc-2500-8500.fits filteredset=filtered.fits withfilteredset=no keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression=true filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=mos1S001-allimc-2500-8500.fits xcolumn=DETX ycolumn=DETY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=yes spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:42.000\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:42.000\n",
      "espfilt:-  HISTOGRAM_METHOD: *CLEANED (flare-free) CORNER EVENTLIST FILE* = mos1S001-corevc-2500-8500.fits\n",
      "espfilt:-  *Flare free corner eventlist evselect command =\n",
      "evselect:- Executing (routine): evselect table=/Users/dt237/code/DAXA/docs/source/notebooks/tutorials/daxa_output/archives/PHL1811_made_earlier/processed_data/xmm_pointed/0204310101/P0204310101M1S001MIEVLI0000.FIT:EVENTS filteredset=mos1S001-corevc-2500-8500.fits withfilteredset=yes keepfilteroutput=yes flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression='(PATTERN<=12)&&GTI(mos1S001-gti-2500-8500.fits,TIME)&&((FLAG & 0x766aa000)==0)&&!(CIRCLE(100,-200,17700,DETX,DETY)||CIRCLE(834,135,17100,DETX,DETY)||CIRCLE(770,-803,17100,DETX,DETY)||BOX(-20,-17000,6500,500,0,DETX,DETY)||BOX(5880,-20500,7500,1500,10,DETX,DETY)||BOX(-5920,-20500,7500,1500,350,DETX,DETY)||BOX(-20,-20000,5500,500,0,DETX,DETY)||BOX(-12900,16000,250,4000,0,DETX,DETY)||BOX(80,18600,150,1300,0,DETX,DETY)||BOX(-10,-18800,125,1500,0,DETX,DETY))' filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=image.fits xcolumn=RAWX ycolumn=RAWY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=no spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:43.000\n",
      "evselect:- selected 11710 rows from the input table.\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:43.000\n",
      "espfilt:-  HISTOGRAM_METHOD: *CLEANED (flare-free) CORNER IMAGE FILE* = mos1S001-corimc-2500-8500.fits\n",
      "espfilt:-  *Flare free corner image evselect command =\n",
      "evselect:- Executing (routine): evselect table=mos1S001-corevc-2500-8500.fits filteredset=filtered.fits withfilteredset=no keepfilteroutput=no flagcolumn=EVFLAG flagbit=-1 destruct=yes dssblock='' expression=true filtertype=expression cleandss=no updateexposure=yes filterexposure=yes writedss=yes blockstocopy='' attributestocopy='' energycolumn=PHA zcolumn=WEIGHT zerrorcolumn=EWEIGHT withzerrorcolumn=no withzcolumn=no ignorelegallimits=no imageset=mos1S001-corimc-2500-8500.fits xcolumn=DETX ycolumn=DETY ximagebinsize=1 yimagebinsize=1 squarepixels=no ximagesize=600 yimagesize=600 imagebinning=imageSize ximagemin=1 ximagemax=640 withxranges=no yimagemin=1 yimagemax=640 withyranges=no imagedatatype=Real64 withimagedatatype=no raimagecenter=0 decimagecenter=0 withcelestialcenter=no withimageset=yes spectrumset=spectrum.fits spectralbinsize=5 specchannelmin=0 specchannelmax=11999 withspecranges=no nonStandardSpec=no withspectrumset=no rateset=rate.fits timecolumn=TIME timebinsize=1 timemin=0 timemax=1000 withtimeranges=no maketimecolumn=no makeratecolumn=no withrateset=no histogramset=histo.fits histogramcolumn=TIME histogrambinsize=1 histogrammin=0 histogrammax=1000 withhistoranges=no withhistogramset=no  -w 1 -V 4\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] started:  2024-04-10T19:55:43.000\n",
      "evselect:- evselect (evselect-3.71.1)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:43.000\n",
      "espfilt:-  HISTOGRAM_METHOD: Adding residuals to cleaned event lists\n",
      "espfilt:- Normalization =  1252.878\n",
      "espfilt:- Width         =     0.173\n",
      "espfilt:- Center        =     0.750\n",
      "espfilt:-  HISTOGRAM_METHOD: Return with no errors\n",
      "espfilt:-  ESPFILT: **** keepinterfiles NOT set\n",
      "espfilt:-  ESPFILT: **** Deleting these intermediary files:\n",
      "espfilt:-  Unfiltered FOV image: mos1S001-fovim-2500-8500.fits\n",
      "espfilt:-  Corner-only image: mos1S001-corim-2500-8500.fits\n",
      "espfilt:-  GTI text file for gtibuild: mos1S001-gti-2500-8500.txt\n",
      "espfilt:- espfilt (espfilt-4.3)  [xmmsas_20211130_0941-20.0.0] ended:    2024-04-10T19:55:43.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prev_arch.process_logs['xmm_pointed']['espfilt']['0204310101M1S001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc8015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3bddf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xmm_pointed': {'cif_build': {},\n",
       "  'odf_ingest': {},\n",
       "  'epchain': {},\n",
       "  'emchain': {},\n",
       "  'espfilt': {'0502671101M2S002': [' raised by  - '],\n",
       "   '0502671101PNS003': ['noCounts raised by espfilt - All histo counts are zero! Check your FOV Lightcurve!']},\n",
       "  'cleaned_evt_lists': {},\n",
       "  'merge_subexposures': {}},\n",
       " 'chandra': {},\n",
       " 'nustar_pointed': {},\n",
       " 'rosat_all_sky': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_arch.process_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28fe7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xmm_pointed': {'0502671101M2S002': \"** espfilt: warning (SingularMatrix), No Count Rate Histogram Produced\\n** espfilt: error (FITSIO), FITS error 402 while accessing file 'mos2S002-allevc-2500-8500.fits': bad float to string conversion\\nError in ffd2e: double value is a NaN or INDEF\\n\\n\"}}\n"
     ]
    }
   ],
   "source": [
    "print(prev_arch.get_process_raw_error_logs('espfilt', full_ident=\"0502671101M2S002\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7165b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xmm_pointed': {'0502671101PNS003': '** evselect: warning (NoWCS), No WCS information available for image column DETX.\\n** evselect: warning (SummaryOfWarnings), \\n   warning NoWCS silently occurred 1 times\\n** evselect: warning (NoWCS), No WCS information available for image column DETX.\\n** evselect: warning (SummaryOfWarnings), \\n   warning NoWCS silently occurred 1 times\\n** espfilt: error (noCounts), All histo counts are zero! Check your FOV Lightcurve!\\nmv: rename pnS003-gti-2500-8500.fits to ../PNS003-gti-2500-8500.fits: No such file or directory\\nmv: rename pnS003-allevc-2500-8500.fits to ../PNS003-allevc-2500-8500.fits: No such file or directory\\nmv: rename pnS003-hist-2500-8500.qdp to ../PNS003-hist-2500-8500.qdp: No such file or directory\\n'}}\n"
     ]
    }
   ],
   "source": [
    "print(prev_arch.get_process_raw_error_logs('espfilt', full_ident=\"0502671101PNS003\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
