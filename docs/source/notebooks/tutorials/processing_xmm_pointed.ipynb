{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0b85df",
   "metadata": {},
   "source": [
    "# Processing raw XMM-Newton Pointed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fc3de",
   "metadata": {},
   "source": [
    "This tutorial will teach you how to use DAXA to process raw XMM-Newton data into a science ready state using one line of Python code (or several lines, if you wish to have more control over the settings for each step). **This relies on there being an initialised (either manually before launching Python, or in your bash profile/rc) backend installation of the XMM Science Analysis System (SAS), including accessible calibration files** - DAXA will check for such an installation, and will not allow processing to start without it.\n",
    "\n",
    "**All DAXA processing steps will parallelise as much as possible - processes running on different ObsIDs/instruments/sub-exposures will be run simultaneously (if cores are available)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa16c92",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a047708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daxa.mission import XMMPointed\n",
    "from daxa.archive import Archive\n",
    "from daxa.process.simple import full_process_xmm\n",
    "from daxa.process.xmm.setup import cif_build, odf_ingest\n",
    "from daxa.process.xmm.assemble import emchain, epchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ef9b5",
   "metadata": {},
   "source": [
    "## An Archive to be processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ead4d3",
   "metadata": {},
   "source": [
    "Every processing function implemented in DAXA takes an Archive instance as its first argument; if you don't already know what that is then you should go back and read the following tutorials:\n",
    "\n",
    "* [Creating a DAXA archive](archives.html) - This explains how to create an archive, load an existing archive, and the various properties and features of DAXA archives.\n",
    "* [Using DAXA missions](missions.html) - Here we explain what DAXA mission classes are and how to use them to select only the data you need.\n",
    "\n",
    "Here we create an archive of XMM observations of the galaxy cluster Abell 907:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a14597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dt237/code/DAXA/daxa/mission/xmm.py:83: UserWarning: 140 of the 17689 observations located for this mission have been removed due to NaN RA or Dec values\n",
      "  self._fetch_obs_info()\n",
      "Downloading XMM-Newton Pointed data: 100%|██████████████████████████████████████| 3/3 [00:36<00:00, 12.05s/it]\n"
     ]
    }
   ],
   "source": [
    "xm = XMMPointed()\n",
    "xm.filter_on_name('A907')\n",
    "arch = Archive('Abell907', xm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e446f2",
   "metadata": {},
   "source": [
    "## One-line solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fcc63",
   "metadata": {},
   "source": [
    "Though we provide individual functions that wrap the various steps required to reduce and prepare XMM data, and they can be used separately for greater control over the configuration parameters, we also include a one-line solution which executes the processing steps with default configuration.\n",
    "\n",
    "We believe that the default parameters are adequate for most use cases, and this allows for users unfamiliar with the intricacies of XMM data to easily start working with it. Executing the following will automatically generate cleaned event lists for MOS1, MOS2, PN, RGS1, and RGS2 (if they were selected during mission creation), as well as images and exposure maps for MOS1, MOS2, and PN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9b53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XMM-Newton Pointed - Generating calibration files: 100%|████████████████████████| 3/3 [00:19<00:00,  6.51s/it]\n",
      "XMM-Newton Pointed - Generating ODF summary files: 100%|████████████████████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "XMM-Newton Pointed - Assembling PN and PN-OOT event lists: 100%|████████████████| 3/3 [03:37<00:00, 72.36s/it]\n",
      "XMM-Newton Pointed - Assembling MOS event lists: 100%|██████████████████████████| 6/6 [01:22<00:00, 13.70s/it]\n",
      "XMM-Newton Pointed - Finding PN/MOS soft-proton flares: 100%|███████████████████| 9/9 [00:17<00:00,  1.93s/it]\n",
      "XMM-Newton Pointed - Generating cleaned PN/MOS event lists: 100%|███████████████| 8/8 [00:03<00:00,  2.62it/s]\n",
      "XMM-Newton Pointed - Generating final PN/MOS event lists: 100%|████████████████| 8/8 [00:00<00:00, 120.67it/s]\n",
      "Generating products of type(s) ccf: 100%|███████████████████████████████████████| 3/3 [00:19<00:00,  6.37s/it]\n",
      "Generating products of type(s) image: 100%|█████████████████████████████████████| 8/8 [00:01<00:00,  7.19it/s]\n",
      "Generating products of type(s) expmap: 100%|████████████████████████████████████| 8/8 [00:22<00:00,  2.84s/it]\n",
      "Generating products of type(s) image: 100%|█████████████████████████████████████| 8/8 [00:01<00:00,  7.01it/s]\n",
      "Generating products of type(s) expmap: 100%|████████████████████████████████████| 8/8 [00:22<00:00,  2.84s/it]\n"
     ]
    }
   ],
   "source": [
    "full_process_xmm(arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ccb11",
   "metadata": {},
   "source": [
    "## Breaking down the XMM processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012e67a",
   "metadata": {},
   "source": [
    "### Setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957e3d8",
   "metadata": {},
   "source": [
    "These functions set up the necessary environment/files for the further processing/reduction of XMM data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a344d",
   "metadata": {},
   "source": [
    "#### Building calibration files (cif_build)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb34481",
   "metadata": {},
   "source": [
    "The [cif_build function](../../daxa.process.xmm.html#daxa.process.xmm.setup.cif_build) function is a wrapper for the XMM SAS tool of the same name - it assembles a CIF, which points other SAS tools to the current calibration files required for whatever XMM instrument they are working on.\n",
    "\n",
    "Only the `analysis_date` parameter of this function affects the files produced by this function (other things can be controlled, such as the number of cores or timeout) - this date determines which calibration files are selected for the generated CIF, and the default is the current date - another date can be passed as a Python datetime object.\n",
    "\n",
    "**All other processing steps depend on this one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db18636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cif_build in module daxa.process.xmm.setup:\n",
      "\n",
      "cif_build(obs_archive: daxa.archive.base.Archive, num_cores: int = 9, disable_progress: bool = False, analysis_date: Union[str, datetime.datetime] = 'now', timeout: astropy.units.quantity.Quantity = None) -> Tuple[dict, dict, dict, str, int, bool, astropy.units.quantity.Quantity]\n",
      "    A DAXA Python interface for the SAS cifbuild command, used to generate calibration files for XMM observations\n",
      "    prior to processing. The observation date is supplied by the XMM mission instance(s), and is the date when the\n",
      "    observation was started (as acquired from the XSA).\n",
      "    \n",
      "    :param Archive obs_archive: An Archive instance containing XMM mission instances for which observation calibration\n",
      "        files should be generated. This function will fail if no XMM missions are present in the archive.\n",
      "    :param int num_cores: The number of cores to use, default is set to 90% of available.\n",
      "    :param bool disable_progress: Setting this to true will turn off the SAS generation progress bar.\n",
      "    :param str/datetime analysis_date: The analysis date for which to generate calibration file. The default is\n",
      "        'now', but this parameter can be used to create calibration files as they would have been on a past date.\n",
      "    :param Quantity timeout: The amount of time each individual process is allowed to run for, the default is None.\n",
      "        Please note that this is not a timeout for the entire cif_build process, but a timeout for individual\n",
      "        ObsID processes.\n",
      "    :return: Information required by the SAS decorator that will run commands. Top level keys of any dictionaries are\n",
      "        internal DAXA mission names, next level keys are ObsIDs. The return is a tuple containing a) a dictionary of\n",
      "        bash commands, b) a dictionary of final output paths to check, c) a dictionary of extra info (in this case\n",
      "        obs and analysis dates), d) a generation message for the progress bar, e) the number of cores allowed, and\n",
      "        f) whether the progress bar should be hidden or not.\n",
      "    :rtype: Tuple[dict, dict, dict, str, int, bool, Quantity]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cif_build)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59a7bc",
   "metadata": {},
   "source": [
    "#### Summarising the available data files (odf_ingest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7b120",
   "metadata": {},
   "source": [
    "The [odf_ingest function](../../daxa.process.xmm.html#daxa.process.xmm.setup.odf_ingest) function simply examines the observation data file (ODF) directory, and determines the instruments (including observing modes and sub-exposures) that have data present - it then creates a SAS summary file.\n",
    "\n",
    "Our implementation of this function wraps the original SAS tool, and then adds a second step - this parses the SAS summary file and extracts the information that is relevant to whether we can use a particular instrument (and sub-exposure of an instrument) for astrophysics. This is what populates the XMM entry in the `observation_summaries` property of the archive class.\n",
    "\n",
    "**All subsequent steps depend on this one - and observation_summaries will have no XMM entry until this is run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eafc732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function odf_ingest in module daxa.process.xmm.setup:\n",
      "\n",
      "odf_ingest(obs_archive: daxa.archive.base.Archive, num_cores: int = 9, disable_progress: bool = False, timeout: astropy.units.quantity.Quantity = None)\n",
      "    This function runs the SAS odfingest task, which creates a summary of the raw data available in the ODF\n",
      "    directory, and is used by many SAS processing tasks.\n",
      "    \n",
      "    :param Archive obs_archive: An Archive instance containing XMM mission instances for which observation summary\n",
      "        files should be generated. This function will fail if no XMM missions are present in the archive.\n",
      "    :param int num_cores: The number of cores to use, default is set to 90% of available.\n",
      "    :param bool disable_progress: Setting this to true will turn off the SAS generation progress bar.\n",
      "    :param Quantity timeout: The amount of time each individual process is allowed to run for, the default is None.\n",
      "        Please note that this is not a timeout for the entire odf_ingest process, but a timeout for individual\n",
      "        ObsID processes.\n",
      "    :return: Information required by the SAS decorator that will run commands. Top level keys of any dictionaries are\n",
      "        internal DAXA mission names, next level keys are ObsIDs. The return is a tuple containing a) a dictionary of\n",
      "        bash commands, b) a dictionary of final output paths to check, c) a dictionary of extra info (in this case\n",
      "        obs and analysis dates), d) a generation message for the progress bar, e) the number of cores allowed, and\n",
      "        f) whether the progress bar should be hidden or not.\n",
      "    :rtype: Tuple[dict, dict, dict, str, int, bool, Quantity]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(odf_ingest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f489ea8",
   "metadata": {},
   "source": [
    "### EPIC Cameras (CCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764de41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e798a17",
   "metadata": {},
   "source": [
    "#### Assembling whole-camera MOS initial event lists (emchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839696a4",
   "metadata": {},
   "source": [
    "The [emchain function](../../daxa.process.xmm.html#daxa.process.xmm.assemble.emchain) is what assembles the raw, separate-CCD-level, event lists and files into a single raw events list for a whole XMM MOS camera exposure. If there are **multiple sub-exposures** which DAXA has identified as being usable, then a separate raw event list is created for each of them - they are combined in a later processing step.\n",
    "\n",
    "We have implemented this method so that MOS1 and MOS2 (and sub-exposures, if present) data are processed in parallel for a given observation (and all observations are processed in parallel as well).\n",
    "\n",
    "Only the `process_unscheduled` argument passed to emchain can change the files produced, as it controls whether unscheduled sub-exposures should be processed or not - the default is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b3a3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function emchain in module daxa.process.xmm.assemble:\n",
      "\n",
      "emchain(obs_archive: daxa.archive.base.Archive, process_unscheduled: bool = True, num_cores: int = 9, disable_progress: bool = False, timeout: astropy.units.quantity.Quantity = None)\n",
      "    This function runs the emchain SAS process on XMM missions in the passed archive, which assembles the\n",
      "    MOS-specific ODFs into combined photon event lists - rather than the per CCD files that existed before. The\n",
      "    emchain manual can be found here (https://xmm-tools.cosmos.esa.int/external/sas/current/doc/emchain.pdf) and\n",
      "    gives detailed explanations of the process.\n",
      "    \n",
      "    The DAXA wrapper does not allow emchain to automatically loop through all the sub-exposures for a given\n",
      "    ObsID-MOSX combo, but rather creates a separate process call for each of them. This allows for greater\n",
      "    parallelisation (if on a system with a significant core count), but also allows the same level of granularity\n",
      "    in the logging of processing of different sub-exposures as in DAXA's epchain implementation.\n",
      "    \n",
      "    The particular CCDs to be processed are not specified in emchain, unlike in epchain, because it can sometimes\n",
      "    have unintended consequences. For instance processing a MOS observation in FastUncompressed mode, with timing\n",
      "    on CCD 1 and imaging everywhere else, can cause emchain to fail (even though no actual failure occurs) because\n",
      "    the submode is set to Unknown, rather than FastUncompressed.\n",
      "    \n",
      "    :param Archive obs_archive: An Archive instance containing XMM mission instances with MOS observations for\n",
      "        which emchain should be run. This function will fail if no XMM missions are present in the archive.\n",
      "    :param bool process_unscheduled: Whether this function should also process sub-exposures marked 'U', for\n",
      "        unscheduled. Default is True, in which case they will be processed.\n",
      "    :param int num_cores: The number of cores to use, default is set to 90% of available.\n",
      "    :param bool disable_progress: Setting this to true will turn off the SAS generation progress bar.\n",
      "    :param Quantity timeout: The amount of time each individual process is allowed to run for, the default is None.\n",
      "        Please note that this is not a timeout for the entire emchain process, but a timeout for individual\n",
      "        ObsID-subexposure processes.\n",
      "    :return: Information required by the SAS decorator that will run commands. Top level keys of any dictionaries are\n",
      "        internal DAXA mission names, next level keys are ObsIDs. The return is a tuple containing a) a dictionary of\n",
      "        bash commands, b) a dictionary of final output paths to check, c) a dictionary of extra info (in this case\n",
      "        obs and analysis dates), d) a generation message for the progress bar, e) the number of cores allowed, and\n",
      "        f) whether the progress bar should be hidden or not.\n",
      "    :rtype: Tuple[dict, dict, dict, str, int, bool, Quantity]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(emchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3e305",
   "metadata": {},
   "source": [
    "#### Assembling whole-camera PN initial event lists (epchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e6cd3",
   "metadata": {},
   "source": [
    "The [epchain function](../../daxa.process.xmm.html#daxa.process.xmm.assemble.epchain) serves much the same purpose as emchain, but for PN camera data. There is only one PN camera, but the presence of multiple sub-exposures is still possible. This function generates raw, whole-camera, event lists just like emchain, but also creates whole-camera out-of-time (OOT) event lists, which attempts to identify event lists that were detected during a CCD readout (this can leave a characteristic streak in the direction of readout for bright sources in PN observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "571484e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function epchain in module daxa.process.xmm.assemble:\n",
      "\n",
      "epchain(obs_archive: daxa.archive.base.Archive, process_unscheduled: bool = True, num_cores: int = 9, disable_progress: bool = False, timeout: astropy.units.quantity.Quantity = None)\n",
      "    This function runs the epchain SAS process on XMM missions in the passed archive, which assembles the\n",
      "    PN-specific ODFs into combined photon event lists - rather than the per CCD files that existed before. A run of\n",
      "    epchain for out of time (OOT) events is also performed as part of this function call. The epchain manual can be\n",
      "    found here (https://xmm-tools.cosmos.esa.int/external/sas/current/doc/epchain.pdf) and gives detailed\n",
      "    explanations of the process.\n",
      "    \n",
      "    Per the advice of the SAS epchain manual, the OOT event list epchain call is performed first, and its intermediate\n",
      "    files are saved and then used for the normal call to epchain.\n",
      "    \n",
      "    :param Archive obs_archive: An Archive instance containing XMM mission instances with PN observations for\n",
      "        which epchain should be run. This function will fail if no XMM missions are present in the archive.\n",
      "    :param bool process_unscheduled: Whether this function should also process sub-exposures marked 'U', for\n",
      "        unscheduled. Default is True, in which case they will be processed.\n",
      "    :param int num_cores: The number of cores to use, default is set to 90% of available.\n",
      "    :param bool disable_progress: Setting this to true will turn off the SAS generation progress bar.\n",
      "    :param Quantity timeout: The amount of time each individual process is allowed to run for, the default is None.\n",
      "        Please note that this is not a timeout for the entire epchain process, but a timeout for individual\n",
      "        ObsID-subexposure processes.\n",
      "    :return: Information required by the SAS decorator that will run commands. Top level keys of any dictionaries are\n",
      "        internal DAXA mission names, next level keys are ObsIDs. The return is a tuple containing a) a dictionary of\n",
      "        bash commands, b) a dictionary of final output paths to check, c) a dictionary of extra info (in this case\n",
      "        obs and analysis dates), d) a generation message for the progress bar, e) the number of cores allowed, and\n",
      "        f) whether the progress bar should be hidden or not.\n",
      "    :rtype: Tuple[dict, dict, dict, str, int, bool, Quantity]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(epchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334d847",
   "metadata": {},
   "source": [
    "### Reflection Grating Spectrometer (RGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d140c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a0f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "885fd8cb",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
